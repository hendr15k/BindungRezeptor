import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import m2cgen as m2c
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import json
import datetime

def calculate_descriptors(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if not mol:
            return None
        # We use descriptors that are available via PubChem API or easy to calculate
        # PubChem returns: MolecularWeight, XLogP, TPSA, HBondDonorCount, HBondAcceptorCount, RotatableBondCount
        # RDKit equivalents:
        mw = Descriptors.MolWt(mol)
        logp = Descriptors.MolLogP(mol)
        tpsa = Descriptors.TPSA(mol)
        hbd = Descriptors.NumHDonors(mol)
        hba = Descriptors.NumHAcceptors(mol)
        rot_bonds = Descriptors.NumRotatableBonds(mol)

        return [mw, logp, tpsa, hbd, hba, rot_bonds]
    except Exception as e:
        return None

def train():
    print("Loading data...")
    try:
        df = pd.read_csv('data/chembl_raw.csv')
    except FileNotFoundError:
        print("Error: data/chembl_raw.csv not found. Please run fetch_data.py first.")
        return

    X = []
    y = []

    print("Calculating descriptors...")
    for idx, row in df.iterrows():
        desc = calculate_descriptors(row['SMILES'])
        if desc:
            X.append(desc)
            y.append(row['Target'])

    print(f"Valid samples: {len(X)}")

    X = np.array(X)
    y = np.array(y)

    # Train/Test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print("Training Random Forest...")
    # Keep max_depth small to reduce JS file size
    clf = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=42)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"Test Accuracy: {acc:.2f}")

    print("Exporting model to JS...")
    code = m2c.export_to_javascript(clf, function_name="predictClass")

    classes = clf.classes_
    print(f"Classes: {classes}")

    class_map_js = "const MODEL_CLASSES = " + json.dumps(classes.tolist()) + ";\n"

    # Metadata about the model
    metadata = f"""
/**
 * Model generated on {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
 * Test Accuracy: {acc:.2f}
 * Target Classes: {', '.join(classes)}
 */
"""

    with open('js/model.js', 'w') as f:
        f.write(metadata)
        f.write(code)
        f.write("\n\n")
        f.write(class_map_js)
        f.write("""
function predictWithModel(inputFeatures) {
    if (!inputFeatures || inputFeatures.length !== 6) {
        console.error("Invalid input features. Expected 6 features: [MW, LogP, TPSA, HBD, HBA, RotBonds]");
        return [];
    }

    // predictClass is generated by m2cgen
    const scores = predictClass(inputFeatures);

    let sum = 0;
    for(let s of scores) sum += s;

    let results = [];
    for(let i=0; i<scores.length; i++) {
        results.push({
            name: MODEL_CLASSES[i],
            probability: sum > 0 ? scores[i] / sum : 0
        });
    }

    results.sort((a,b) => b.probability - a.probability);
    return results;
}

// Export for Node.js testing if running in that environment
if (typeof module !== 'undefined' && module.exports) {
    // This is a bit hacky because predictClass is global, but valid for m2cgen output in browser usually
    // We define a global wrapper if needed or just let the eval script handle it.
}
""")

    print("Model saved to js/model.js")

if __name__ == "__main__":
    train()
